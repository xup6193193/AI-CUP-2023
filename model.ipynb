{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill, csv, os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import librosa\n",
    "import numpy as np\n",
    "import dill\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "voice_data = dill.load(open('voice_data.joblib', 'rb'))\n",
    "\n",
    "train_X = voice_data.train_X\n",
    "train_Y = voice_data.train_Y\n",
    "train_sounds = voice_data.train_sounds\n",
    "\n",
    "public_test_X = voice_data.public_test_X\n",
    "public_test_Y = voice_data.public_test_Y\n",
    "public_test_sounds = voice_data.public_test_sounds\n",
    "\n",
    "private_test_X = voice_data.private_test_X\n",
    "private_test_Y = voice_data.private_test_Y\n",
    "private_test_sounds = voice_data.private_test_sounds\n",
    "\n",
    "to_add = []\n",
    "for i in range(len(train_X)):\n",
    "    if train_Y[i][0] == 3:\n",
    "        to_add.append(i)\n",
    "    elif train_Y[i][0] == 4:\n",
    "        to_add.append(i)\n",
    "\n",
    "train_features = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "\n",
    "train_X_ = list(train_X)\n",
    "train_Y_ = list(train_Y)\n",
    "for i in to_add:\n",
    "    train_X_.append(train_X[i])\n",
    "    train_Y_.append(train_Y[i])\n",
    "    train_X_.append(train_X[i])\n",
    "    train_Y_.append(train_Y[i])\n",
    "\n",
    "# turn 1~5 to 0~4\n",
    "train_Y = [i-1 for i in train_Y]\n",
    "public_test_Y = [i-1 for i in public_test_Y]\n",
    "private_test_Y = [i-1 for i in private_test_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as statsmodels\n",
    "from hurst import compute_Hc\n",
    "from librosa.feature import mfcc\n",
    "\n",
    "# feature function\n",
    "def get_mfccs(sound):\n",
    "    mfccs = mfcc(y=sound, sr=44100, n_mfcc=13)\n",
    "    mfccs = np.mean(mfccs, axis=1)\n",
    "    return mfccs\n",
    "\n",
    "# AR parameters for the sound\n",
    "def get_ar(sound):\n",
    "    '''\n",
    "    Input: sound(1D array)\n",
    "    Output: AR parameters(1D array)\n",
    "    '''\n",
    "    AR = statsmodels.regression.linear_model.burg(sound, 14)[0]\n",
    "    return AR\n",
    "\n",
    "# Hurst Exponent \n",
    "def get_hurst(sound):\n",
    "    '''\n",
    "    Input: sound(1D array)\n",
    "    Output: Hurst exponent(float)\n",
    "    '''\n",
    "    H, c, data = compute_Hc(sound, kind='random_walk', simplified=True)\n",
    "    H = np.array([H])\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [10:24<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def merge_feature(feature1, feature2):\n",
    "    '''\n",
    "    Input: feature1, feature2(1D array)\n",
    "    Output: merged feature(1D array)\n",
    "    '''\n",
    "    feature = np.concatenate((feature1, feature2))\n",
    "    return feature\n",
    "\n",
    "def get_feature(rows, sounds):\n",
    "    features = []\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        # feature = merge_feature(rows[i][1:], get_mfccs(sounds[i]))\n",
    "        feature = merge_feature(rows[i], get_hurst(sounds[i]))\n",
    "        feature = merge_feature(feature, get_ar(sounds[i]))\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "train_features = get_feature(train_X, train_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to k folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 220, 4: 32, 0: 536, 2: 168, 3: 44}\n"
     ]
    }
   ],
   "source": [
    "count = {}\n",
    "for i in train_Y:\n",
    "    if i[0] not in count:\n",
    "        count[i[0]] = 1\n",
    "    else:\n",
    "        count[i[0]] += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 12, 'learning_rate':  0.15, 'objective': 'multi:softmax','colsample_bytree': 0.8, 'random_state': seed}\n",
    "model = xgb.XGBClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [i[1:] for i in train_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = []\n",
    "for i in range(len(train_X)):\n",
    "    if train_Y[i][0] == 3:\n",
    "        to_add.append(i)\n",
    "    elif train_Y[i][0] == 4:\n",
    "        to_add.append(i)\n",
    "\n",
    "train_features = list(train_features)\n",
    "train_Y = list(train_Y)\n",
    "for i in to_add:\n",
    "    train_features.append(train_features[i])\n",
    "    train_Y.append(train_Y[i])\n",
    "    train_features.append(train_features[i])\n",
    "    train_Y.append(train_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       107\n",
      "           1       0.57      0.43      0.49        49\n",
      "           2       0.68      0.50      0.58        30\n",
      "           3       0.86      1.00      0.92        24\n",
      "           4       0.88      1.00      0.93        21\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.74      0.75      0.74       231\n",
      "weighted avg       0.71      0.72      0.71       231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       107\n",
      "           1       0.53      0.33      0.41        48\n",
      "           2       0.71      0.61      0.66        33\n",
      "           3       0.93      1.00      0.96        27\n",
      "           4       0.84      1.00      0.91        16\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.75      0.76      0.75       231\n",
      "weighted avg       0.72      0.74      0.73       231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       114\n",
      "           1       0.60      0.62      0.61        47\n",
      "           2       0.72      0.56      0.63        32\n",
      "           3       0.92      1.00      0.96        23\n",
      "           4       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.77       230\n",
      "   macro avg       0.78      0.80      0.78       230\n",
      "weighted avg       0.77      0.77      0.77       230\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82       113\n",
      "           1       0.42      0.29      0.34        34\n",
      "           2       0.75      0.60      0.67        40\n",
      "           3       0.92      1.00      0.96        22\n",
      "           4       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.77       230\n",
      "   macro avg       0.76      0.75      0.75       230\n",
      "weighted avg       0.75      0.77      0.75       230\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        95\n",
      "           1       0.50      0.33      0.40        42\n",
      "           2       0.55      0.52      0.53        33\n",
      "           3       0.95      1.00      0.97        36\n",
      "           4       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.73       230\n",
      "   macro avg       0.73      0.71      0.72       230\n",
      "weighted avg       0.71      0.73      0.71       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model):\n",
    "    '''\n",
    "    Input: model\n",
    "    Output: model\n",
    "    '''\n",
    "    for train_index, test_index in kf.split(train_features):\n",
    "        X_train, X_test = np.array(train_features)[train_index], np.array(train_features)[test_index]\n",
    "        y_train, y_test = np.array(train_Y)[train_index], np.array(train_Y)[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, sound):\n",
    "    features = get_feature(row, sound)\n",
    "    ids = [i[0] for i in features]\n",
    "    features = [i[1:] for i in features]\n",
    "    features = np.array(features)\n",
    "    y_pred = model.predict(features)\n",
    "    return ids, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [04:21<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "ids, y_pred = predict(private_test_X, private_test_sounds)\n",
    "# save to csv\n",
    "with open('private_pred.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(ids)):\n",
    "        writer.writerow([ids[i], y_pred[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [04:54<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "ids, y_pred = predict(public_test_X, public_test_sounds)\n",
    "# save to csv\n",
    "with open('public_pred.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(ids)):\n",
    "        writer.writerow([ids[i], y_pred[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
